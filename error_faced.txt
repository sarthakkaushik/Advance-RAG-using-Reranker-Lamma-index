Got the below error : while running below code 

Error:
ValueError: Couldn't instantiate the backend tokenizer from one of: (1) a `tokenizers` library serialization file, (2) a slow tokenizer instance to convert or (3) an equivalent slow tokenizer class to instantiate and convert. You need to have sentencepiece installed to convert a slow tokenizer to a fast one.

Solution:

I resolved it.

Uninstalled transformers
Installed transformers sentencepiece like this : !pip install --no-cache-dir transformers sentencepiece