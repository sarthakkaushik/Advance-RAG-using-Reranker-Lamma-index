{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the openai key\n",
    "load_dotenv()\n",
    "open_api_key=os.environ['OPENAI_API_KEY']\n",
    "openai.api_key=open_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and cchunking the documents\n",
    "\n",
    "documents=SimpleDirectoryReader(\n",
    "    input_files=[\"../data/Machine Learning Engineering with Python-2023.pdf\"]\n",
    ").load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "463 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Machine Learning Engineering with Python\n",
      "Second Edition\n",
      "Copyright © 2023 Packt Publishing\n",
      "All rights reserved. No part of this book may be reproduced, stored in a retrieval system, or transmitted in \n",
      "any form or by any means, without the prior written permission of the publisher, except in the case of brief \n",
      "quotations embedded in critical articles or reviews.\n",
      "Every effort has been made in the preparation of this book to ensure the accuracy of the information \n",
      "presented. However, the information contained in this book is sold without warranty, either express or \n",
      "implied. Neither the author nor Packt Publishing or its dealers and distributors, will be held liable for any \n",
      "damages caused or alleged to have been caused directly or indirectly by this book.\n",
      "Packt Publishing has endeavored to provide trademark information about all of the companies and products \n",
      "mentioned in this book by the appropriate use of capitals. However, Packt Publishing cannot guarantee \n",
      "the accuracy of this information.\n",
      "Publishing Product Manager: Bhavesh Amin\n",
      "Acquisition Editor – Peer Reviews: Gaurav Gavas\n",
      "Project Editor:  Amisha Vathare\n",
      "Content Development Editor:  Elliot Dallow\n",
      "Copy Editor:  Safis Editing\n",
      "Technical Editor:  Anjitha Murali\n",
      "Proofreader:  Safis Editing\n",
      "Indexer: Subalakshmi Govindhan\n",
      "Presentation Designer:  Rajesh Shirsath\n",
      "Developer Relations Marketing Executive: Monika Sangwan\n",
      "First published: November 2021\n",
      "Second edition: August 2023\n",
      "Production reference: 2280823\n",
      "Published by Packt Publishing Ltd. \n",
      "Grosvenor House\n",
      "11 St Paul’s Square\n",
      "Birmingham \n",
      "B3 1RB, UK.\n",
      "ISBN 978-1-83763-196-4\n",
      "www.packt.com\n",
      "\n",
      "1609\n",
      "1434\n",
      "1641\n"
     ]
    }
   ],
   "source": [
    "#Checking the summary of chunked documents\n",
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[2].text)\n",
    "print(len(documents[2].text))\n",
    "print(len(documents[10].text))\n",
    "print(len(documents[22].text))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='69b12ed1-34a5-487a-bc47-d87e5c515cc6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining the all chunked text into single documents\n",
    "from llama_index import Document\n",
    "\n",
    "documnet=Document(tetx=\"\\n\\n\".join([doc.text for doc in documents]))\n",
    "documnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead929ea79594c889dab27a168b68547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarthakkaushik\\.conda\\envs\\Adv_RAG_lamaindx_venv\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sarthakkaushik\\AppData\\Local\\llama_index. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d922694e15b6431b83c80df6f00e33f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791d3b5f760943acba9980ef1a3dfdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2c1f8793af43809b0ab2317419bf72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbf4549fa974363a8cd4925d3e72c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d4ce9ac98d40ce85c3fb08c39d51e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating index\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "#config llm\n",
    "llm= OpenAI(model=\"gpt-3.5-turbo\",temperature=0.1) \n",
    "#config embedding\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "service_context=ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model= embed_model\n",
    ")\n",
    "\n",
    "index= VectorStoreIndex.from_documents([documnet],\n",
    "                                       service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine= index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One way to analyze your own code for security issues is to conduct a thorough code review. This involves carefully examining your code line by line to identify any potential vulnerabilities or weaknesses. Additionally, you can use automated code analysis tools that can scan your code for common security issues and provide recommendations for improvement. Regularly testing your code in different scenarios and environments can also help uncover any security flaws.\n"
     ]
    }
   ],
   "source": [
    "response=query_engine.query(\"How can we analyzing your own code for security issues\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation setup using TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can we analyzing your own code for security issues\n"
     ]
    }
   ],
   "source": [
    "eval_questions = []\n",
    "with open('../eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new question:\n",
    "new_question = \"How to publish in ECR\"\n",
    "eval_questions.append(new_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How can we analyzing your own code for security issues', 'How to publish in ECR']\n"
     ]
    }
   ],
   "source": [
    "print(eval_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦑 Tru initialized with db url sqlite:///default.sqlite .\n",
      "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input statement will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import get_prebuilt_trulens_recorder\n",
    "\n",
    "tru_recorder = get_prebuilt_trulens_recorder(query_engine,\n",
    "                                             app_id=\"Direct Query Engine\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    for question in eval_questions:\n",
    "        response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_cb7363c0389ce919b5cd1da786d268e2</td>\n",
       "      <td>\"How can we analyzing your own code for securi...</td>\n",
       "      <td>\"One way to analyze your own code for security...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_cb7363c0389ce919b5c...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-02T23:34:53.356450\", \"...</td>\n",
       "      <td>2023-12-02T23:34:58.570815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'question': 'How can we analyzing y...</td>\n",
       "      <td>[{'args': {'prompt': 'How can we analyzing you...</td>\n",
       "      <td>[{'args': {'source': '', 'statement': 'One way...</td>\n",
       "      <td>5</td>\n",
       "      <td>202</td>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>{\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_7e475eb8b2506afec9e27a2377f997a5</td>\n",
       "      <td>\"How to publish in ECR\"</td>\n",
       "      <td>\"To publish in ECR, you can follow these steps...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_7e475eb8b2506afec9e...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-02T23:34:58.822650\", \"...</td>\n",
       "      <td>2023-12-02T23:35:12.484323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'args': {'question': 'How to publish in ECR'...</td>\n",
       "      <td>[{'args': {'prompt': 'How to publish in ECR', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>302</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                app_id                                           app_json  \\\n",
       "0  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "1  Direct Query Engine  {\"app_id\": \"Direct Query Engine\", \"tags\": \"-\",...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_cb7363c0389ce919b5cd1da786d268e2   \n",
       "1  record_hash_7e475eb8b2506afec9e27a2377f997a5   \n",
       "\n",
       "                                               input  \\\n",
       "0  \"How can we analyzing your own code for securi...   \n",
       "1                            \"How to publish in ECR\"   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"One way to analyze your own code for security...    -   \n",
       "1  \"To publish in ECR, you can follow these steps...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_cb7363c0389ce919b5c...   \n",
       "1  {\"record_id\": \"record_hash_7e475eb8b2506afec9e...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "1  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2023-12-02T23:34:53.356450\", \"...   \n",
       "1  {\"start_time\": \"2023-12-02T23:34:58.822650\", \"...   \n",
       "\n",
       "                           ts  Context Relevance  Answer Relevance  \\\n",
       "0  2023-12-02T23:34:58.570815                0.0               0.9   \n",
       "1  2023-12-02T23:35:12.484323                0.0               1.0   \n",
       "\n",
       "   Groundedness                            Context Relevance_calls  \\\n",
       "0           1.0  [{'args': {'question': 'How can we analyzing y...   \n",
       "1           NaN  [{'args': {'question': 'How to publish in ECR'...   \n",
       "\n",
       "                              Answer Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'How can we analyzing you...   \n",
       "1  [{'args': {'prompt': 'How to publish in ECR', ...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': '', 'statement': 'One way...        5           202   \n",
       "1                                                NaN       13           302   \n",
       "\n",
       "   total_cost  \n",
       "0    0.000344  \n",
       "1    0.000545  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Adv_RAG_lamaindx_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
